{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "BASE_DIR = Path.cwd()\n",
    "if (BASE_DIR / \"DATA\").exists() is False:\n",
    "    BASE_DIR = BASE_DIR.parent\n",
    "\n",
    "INPUT_CSV = BASE_DIR / \"DATA\" / \"cleaned\" / \"airline_cleaned.csv\"\n",
    "OUTPUT_CSV = BASE_DIR / \"DATA\" / \"with_sentiments\" / \"airline_cleaned_with_sentiment.csv\"\n",
    "\n",
    "OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEXT_COLUMN = \"content\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Set up the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare the texts for sentiment analysis\n",
    "texts = df[TEXT_COLUMN].fillna(\"\").astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data w/ sentiment scores was successfully saved!\n",
      "   sentiment_score\n",
      "0         0.326550\n",
      "1         0.947232\n",
      "2         0.946018\n",
      "3         0.922577\n",
      "4        -0.591914\n"
     ]
    }
   ],
   "source": [
    "# Store sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Perform sentiment analysis in batches\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "\n",
    "        # Get the current batch of texts\n",
    "        batch = texts[i:i+BATCH_SIZE]\n",
    "\n",
    "        # Tokenize the batch of texts\n",
    "        tokens = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Get the model's output logits and convert to probabilities\n",
    "        logits = model(**tokens).logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1).cpu()\n",
    "\n",
    "        # index 0 = negative\n",
    "        # index 1 = neutral\n",
    "        # index 2 = positive\n",
    "\n",
    "        # Calculate the sentiment scores as the difference between positive and negative probabilities\n",
    "        scores = probs[:, 2] - probs[:, 0]\n",
    "\n",
    "        # Append the scores to the list\n",
    "        sentiment_scores.extend(scores.tolist())\n",
    "\n",
    "# Add the sentiment scores to the df\n",
    "df[\"sentiment_score\"] = sentiment_scores\n",
    "\n",
    "# Save the updated df to a new CSV file\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(\"Data w/ sentiment scores was successfully saved!\")\n",
    "print(df[[\"sentiment_score\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data w/ mismatch indicator was successfully saved!\n",
      "Total mismatches: 2399\n",
      "Mismatch rate: 6.51 %\n"
     ]
    }
   ],
   "source": [
    "# Add mismatch indicator\n",
    "SENT_COL = \"sentiment_score\"\n",
    "RATING_COL = \"overall_rating\"\n",
    "MISMATCH_COL = \"mismatch\"\n",
    "\n",
    "# Convert columns to numbers\n",
    "df[SENT_COL] = pd.to_numeric(df[SENT_COL], errors=\"coerce\")\n",
    "df[RATING_COL] = pd.to_numeric(df[RATING_COL], errors=\"coerce\")\n",
    "\n",
    "# Define mismatch conditions\n",
    "pos_mismatch = (df[SENT_COL] > 0.05) & (df[RATING_COL] <= 4)\n",
    "neg_mismatch = (df[SENT_COL] < -0.05) & (df[RATING_COL] >= 8)\n",
    "\n",
    "# Create df with mismatch indicator column\n",
    "df[MISMATCH_COL] = (pos_mismatch | neg_mismatch).astype(int)\n",
    "\n",
    "# Save df with mismatch indicator as a new CSV file\n",
    "OUTPUT_PATH = BASE_DIR / \"DATA\" / \"with_mismatch\" / \"airline_with_mismatch.csv\"\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"Data w/ mismatch indicator was successfully saved!\")\n",
    "print(\"Total mismatches:\", df[MISMATCH_COL].sum())\n",
    "print(\"Mismatch rate:\", round(df[MISMATCH_COL].mean() * 100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
